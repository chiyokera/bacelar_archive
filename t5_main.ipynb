{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ここではrulebase_datasetを用いて実際にテキストを生成していく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import MeCab\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "df_rules = pd.read_csv('/path/to/rulebase_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前学習済みモデル\n",
    "PRETRAINED_MODEL_NAME = \"retrieva-jp/t5-base-short\"\n",
    "\n",
    "# 転移学習済みモデル\n",
    "MODEL_DIR = \"/path/to/t5model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csvファイルの'input(ルールベース)'と'output'から各行を抽出したものをdf_rulesとする\n",
    "def zenkaku_to_hankaku(text):\n",
    "    zenkaku = 'ａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺ'\n",
    "    hankaku = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "    translation = str.maketrans(zenkaku, hankaku)\n",
    "    return text.translate(translation)\n",
    "\n",
    "\n",
    "all_data = []\n",
    "for i in range(len(df_rules)):\n",
    "    df_rule = df_rules.iloc[i,:]\n",
    "    input = zenkaku_to_hankaku(df_rule['input'])\n",
    "    output = zenkaku_to_hankaku(df_rule['output'])\n",
    "    if len(input) > 0 and len(output) > 0:\n",
    "        all_data.append({\"input\": input.lower(), \"output\": output.lower()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1522it [00:00, 106878.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#t5dataフォルダ内の空のtrain~test.tsvファイルにそれぞれ0.85:0.10:0.05の割合でデータを割り振る\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(1234)\n",
    "random.shuffle(all_data)\n",
    "\n",
    "def to_line(data):\n",
    "    input = data[\"input\"]\n",
    "    output = data[\"output\"]\n",
    "    assert len(input) > 0 and len(output) > 0\n",
    "    return f\"{input}\\t{output}\\n\"\n",
    "\n",
    "data_size = len(all_data)\n",
    "train_ratio, dev_ratio, test_ratio = 0.85, 0.10, 0.05\n",
    "\n",
    "with open(f\"/home/tanaka/Archive/t5data/train.tsv\", \"w\", encoding=\"utf-8\") as f_train, \\\n",
    "    open(f\"/home/tanaka/Archive/t5data/valid.tsv\", \"w\", encoding=\"utf-8\") as f_dev, \\\n",
    "    open(f\"/home/tanaka/Archive/t5data/test.tsv\", \"w\", encoding=\"utf-8\") as f_test:\n",
    "\n",
    "    for i, data in tqdm(enumerate(all_data)):\n",
    "        line = to_line(data)\n",
    "        if i < train_ratio * data_size:\n",
    "            f_train.write(line)\n",
    "        elif i < (train_ratio + dev_ratio) * data_size:\n",
    "            f_dev.write(line)\n",
    "        else:\n",
    "            f_test.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 10:25:05.635799: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-19 10:25:05.635850: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-19 10:25:05.635870: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-19 10:25:05.645249: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-19 10:25:06.744648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#haggingfaceからT5トークナイザなどをインポート、シードを固定\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "# 乱数シードの設定\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU利用有無\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "\n",
    "# 各種ハイパーパラメータ\n",
    "args_dict = dict(\n",
    "    data_dir=\"/home/tanaka/Archive/t5data\",  # データセットのディレクトリ\n",
    "    model_name_or_path=PRETRAINED_MODEL_NAME,\n",
    "    tokenizer_name_or_path=PRETRAINED_MODEL_NAME,\n",
    "\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    gradient_accumulation_steps=1,\n",
    "\n",
    "    # max_input_length=512,\n",
    "    # max_target_length=64,\n",
    "    # train_batch_size=8,\n",
    "    # eval_batch_size=8,\n",
    "    # num_train_epochs=4,\n",
    "\n",
    "    n_gpu=1 if USE_GPU else 0,\n",
    "    early_stop_callback=False,\n",
    "    fp_16=False,\n",
    "    max_grad_norm=1.0,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ミニバッチ作成かつ、T5入力用にデータ整備（プ－リングなど）\n",
    "    \n",
    "class TsvDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data_dir, type_path, input_max_len=512, target_max_len=512):\n",
    "        self.file_path = os.path.join(data_dir, type_path)\n",
    "\n",
    "        self.input_max_len = input_max_len\n",
    "        self.target_max_len = target_max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "        target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "\n",
    "        source_mask = self.inputs[index][\"attention_mask\"].squeeze()\n",
    "        target_mask = self.targets[index][\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": source_mask,\n",
    "                \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "\n",
    "    def _make_record(self, inp, out):\n",
    "        # ニュースタイトル生成タスク用の入出力形式に変換する。\n",
    "        input = f\"{inp}\"\n",
    "        target = f\"{out}\"\n",
    "        return input, target\n",
    "\n",
    "    def _build(self):\n",
    "        with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                assert len(line) == 2\n",
    "                assert len(line[0]) > 0\n",
    "                assert len(line[1]) > 0\n",
    "\n",
    "                inp = line[0]\n",
    "                out = line[1]\n",
    "\n",
    "                input, target = self._make_record(inp, out)\n",
    "\n",
    "                tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "                    [input], max_length=self.input_max_len, truncation=True,\n",
    "                    padding=\"max_length\", return_tensors=\"pt\"\n",
    "                )\n",
    "\n",
    "                tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "                    [target], max_length=self.target_max_len, truncation=True,\n",
    "                    padding=\"max_length\", return_tensors=\"pt\"\n",
    "                )\n",
    "\n",
    "                self.inputs.append(tokenized_inputs)\n",
    "                self.targets.append(tokenized_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ファインチューニングのためのクラス、pl.lightningを用いた\n",
    "    \n",
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "\n",
    "        # 事前学習済みモデルの読み込み\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
    "\n",
    "        # トークナイザーの読み込み\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path, is_fast=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, decoder_input_ids=None,\n",
    "                decoder_attention_mask=None, labels=None):\n",
    "        \"\"\"順伝搬\"\"\"\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        \"\"\"ロス計算\"\"\"\n",
    "        labels = batch[\"target_ids\"]\n",
    "\n",
    "        # All labels set to -100 are ignored (masked),\n",
    "        # the loss is only computed for labels in [0, ..., config.vocab_size]\n",
    "        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            decoder_attention_mask=batch['target_mask'],\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"訓練ステップ処理\"\"\"\n",
    "        loss = self._step(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"バリデーションステップ処理\"\"\"\n",
    "        loss = self._step(batch)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"テストステップ処理\"\"\"\n",
    "        loss = self._step(batch)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return {\"test_loss\": loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"オプティマイザーとスケジューラーを作成する\"\"\"\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters()\n",
    "                            if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters()\n",
    "                            if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.hparams.learning_rate,\n",
    "                          eps=self.hparams.adam_epsilon)\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer = self.optimizer, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=self.t_total)\n",
    "        \n",
    "        self.scheduler = scheduler\n",
    "\n",
    "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}]\n",
    "\n",
    "    def get_dataset(self, tokenizer, type_path, args):\n",
    "        \"\"\"データセットを作成する\"\"\"\n",
    "        return TsvDataset(\n",
    "            tokenizer=tokenizer,\n",
    "            data_dir=args.data_dir,\n",
    "            type_path=type_path,\n",
    "            input_max_len=args.max_input_length,\n",
    "            target_max_len=args.max_target_length)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"初期設定（データセットの読み込み）\"\"\"\n",
    "        if stage == 'fit' or stage is None:\n",
    "            train_dataset = self.get_dataset(tokenizer=self.tokenizer,\n",
    "                                                type_path=\"train.tsv\", args=self.hparams)\n",
    "            self.train_dataset = train_dataset\n",
    "\n",
    "            val_dataset = self.get_dataset(tokenizer=self.tokenizer,\n",
    "                                            type_path=\"valid.tsv\", args=self.hparams)\n",
    "            self.val_dataset = val_dataset\n",
    "\n",
    "            self.t_total = (\n",
    "                (len(train_dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
    "                // self.hparams.gradient_accumulation_steps\n",
    "                * float(self.hparams.num_train_epochs)\n",
    "                )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"訓練データローダーを作成する\"\"\"\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.hparams.train_batch_size,\n",
    "                          drop_last=True, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"バリデーションデータローダーを作成する\"\"\"\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.hparams.eval_batch_size,\n",
    "                          num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習に用いるハイパーパラメータを設定する\n",
    "args_dict.update({\n",
    "    \"max_input_length\":  600,  # 入力文の最大トークン数\n",
    "    \"max_target_length\": 80,  # 出力文の最大トークン数\n",
    "    \"train_batch_size\":  8,  # 訓練時のバッチサイズ\n",
    "    \"eval_batch_size\":   8,  # テスト時のバッチサイズ\n",
    "    \"num_train_epochs\":  10,  # 訓練するエポック数\n",
    "    })\n",
    "args = argparse.Namespace(**args_dict)\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    devices=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 247 M \n",
      "-----------------------------------------------------\n",
      "247 M     Trainable params\n",
      "0         Non-trainable params\n",
      "247 M     Total params\n",
      "990.311   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0882bb3ca60240d1add93428bf7d9f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd99f7d62ed843f3a952b80870b75497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f28a78a0384430bf292002ab53e41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1361c4695f6246ea8753ca29e6d06b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bbcc0e6563428a82abf3b5a6d33201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16002fc4948f43b3a5b6e235d0a0727b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1229fb8005a64d1ba45fe3780d1018d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa2bfac44d0442ca6d42578b4d5dbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa874485f6fc4db9a78b86fe50e42af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d0d34c40bc49f3bd76df4a90fd6e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd8ef04e4f444df9aa0913e1369e75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f70aa38c924fe682990cae2fb2c8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# 転移学習の実行（GPUを利用すれば1エポック2分程度）\n",
    "model = T5FineTuner(args)\n",
    "trainer = pl.Trainer(**train_params)\n",
    "trainer.fit(model)\n",
    "\n",
    "# 最終エポックのモデルを保存\n",
    "model.tokenizer.save_pretrained(MODEL_DIR)\n",
    "model.model.save_pretrained(MODEL_DIR)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#学習済みモデルを読み込む\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# トークナイザー（SentencePiece）\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_DIR, is_fast=True)\n",
    "\n",
    "# 学習済みモデル\n",
    "trained_model = T5ForConditionalGeneration.from_pretrained(MODEL_DIR)\n",
    "\n",
    "# GPUの利用有無\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "if USE_GPU:\n",
    "    trained_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8c744c5970483ea2ec119b5fff1d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import textwrap\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import metrics\n",
    "\n",
    "# テストデータの読み込み\n",
    "test_dataset = TsvDataset(tokenizer, args_dict[\"data_dir\"], \"test.tsv\",\n",
    "                          input_max_len=args.max_input_length,\n",
    "                          target_max_len=args.max_target_length)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, num_workers=4)\n",
    "\n",
    "trained_model.eval()\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "targets = []\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    input_ids = batch['source_ids']\n",
    "    input_mask = batch['source_mask']\n",
    "    if USE_GPU:\n",
    "        input_ids = input_ids.cuda()\n",
    "        input_mask = input_mask.cuda()\n",
    "\n",
    "    output = trained_model.generate(input_ids=input_ids,\n",
    "        attention_mask=input_mask,\n",
    "        max_length=args.max_target_length,\n",
    "        temperature=1.0,          # 生成にランダム性を入れる温度パラメータ\n",
    "        repetition_penalty=1.5,   # 同じ文の繰り返し（モード崩壊）へのペナルティ\n",
    "        )\n",
    "\n",
    "    output_text = [tokenizer.decode(ids, skip_special_tokens=True,\n",
    "                            clean_up_tokenization_spaces=False)\n",
    "                for ids in output]\n",
    "    target_text = [tokenizer.decode(ids, skip_special_tokens=True,\n",
    "                               clean_up_tokenization_spaces=False)\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    input_text = [tokenizer.decode(ids, skip_special_tokens=True,\n",
    "                               clean_up_tokenization_spaces=False)\n",
    "                for ids in input_ids]\n",
    "\n",
    "    inputs.extend(input_text)\n",
    "    outputs.extend(output_text)\n",
    "    targets.extend(target_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated: 湘南 キッカーは名古。右足を振り抜くが、シュートには持ち込めない\n",
      "actual:    湘南 FKのキッカーの名古が右足を振り抜く。だが、相手の壁に防がれてしまう\n",
      "\n",
      "generated: 鹿島 エヴェラウドがドリブルで持ち上がり、ペナルティエリア手前の中央から右足を振り抜く。しかし、シュートは枠の左にそれてしまう\n",
      "actual:    鹿島 エヴェラウドがパスを受けると、フィジカルの強さを生かしてキープし、前を向く。そのまま持ち込んでペナルティエリア手前の中央からシュートを放つも、槙野にブロックされてしまう\n",
      "\n",
      "generated: 鹿島 右CKを獲得する。キッカーの永戸は左足でアウトスイングのクロスを供給するが、ニアサイドで相手にクリアされてしまう\n",
      "actual:    鹿島 右CKを獲得すると、キッカーは永戸。左足で低い弾道のクロスを入れるも、味方は触れない\n",
      "\n",
      "generated: 神戸 古橋が自陣から右サイドへロングボールを送ると、藤本が抜け出す。藤本はペナルティエリア手前の中央まで駆け上がると、そのままドリブルで持ち上がり、左サイドの敵陣深くからオフサイドの判定を受ける\n",
      "actual:    神戸 後方でのパス回しから、味方が右サイドの敵陣中央へ縦パスを送る。藤本が抜け出して収めるが、オフサイドの判定となってしまう\n",
      "\n",
      "generated: 名古屋 吉田豊が左サイドの敵陣中央からペナルティエリア手前の中央へスルーパスを出す。東が反応するが、ボールはゴールラインを割ってしまう\n",
      "actual:    名古屋 吉田豊が左サイドの敵陣中央からペナルティエリア左のディフェンスラインの裏へ縦パスを入れる。しかし、走り出した柿谷へは合わない\n",
      "\n",
      "generated: 大分 福森が左サイドの敵陣深くでボールを持ち、DFをかわしてシュートを放つ。しかし、Jシミッチに当たってしまい、ゴールには至らない\n",
      "actual:    大分 敵陣でボールをつなぐと、最後は町田からのパスを受けた福森が仕掛け、ペナルティエリア手前の左からシュートを放つ。しかし、相手に当たり、枠をとらえられない\n",
      "\n",
      "generated: 名古屋 味方がペナルティエリア手前の右から左足で浮き球を送ると、山崎がダイレクトでシュートを放つ。しかし、枠をとらえられない\n",
      "actual:    名古屋 山崎がペナルティアーク付近でマテウスとのパス交換を経てペナルティエリア手前の中央からシュートを放つ。しかし、相手DFにブロックされてしまう\n",
      "\n",
      "generated: 仙台 右CKを獲得する。キッカーの松下は左足でアウトスイングのクロスを供給するも、相手にクリアされてしまう\n",
      "actual:    仙台 右CKを獲得する。キッカーの松下が左足でインスイングの低いクロスを供給するが、ニアサイドでDFにクリアされてしまう\n",
      "\n",
      "generated: 名古屋 右CKを獲得する。キッカーのマテウスはショートコーナーを選択すると、宮原がペナルティエリア手前の中央から左足でシュートを放つ。しかし、児玉にパンチングではじかれてしまう\n",
      "actual:    名古屋 マテウスが右サイドの敵陣深くから左足でシュートを放つ。しかし、児玉にはじかれてしまい、ゴールには至らない\n",
      "\n",
      "generated: 柏 右CKを獲得する。キッカーのIシノヅカはゴール前へクロスを入れるが、DFにクリアされてしまう\n",
      "actual:    柏 右サイドからのCKを獲得。キッカーのIシノヅカは右足でクロスをゴール前に蹴り込む。だが、相手にニアサイドでクリアされてしまう\n",
      "\n",
      "generated: 川崎F Lダミアンがペナルティエリア手前の左からペナルティエリア内へ浮き球のパスを入れる。Lダミアンは走り込んでトラップするが、DFにカットされてしまう\n",
      "actual:    川崎F 家長がゴール前へ浮き球のパスを入れると、Lダミアンが収める。しかし、相手DFの対応に遭い、シュートまでは持ち込めない\n",
      "\n",
      "generated: 広島 Dヴィエイラが左サイドの敵陣深くからペナルティエリア手前の中央へ鋭いパスを送る。柏が受けてシュートを放つも、相手にブロックされてしまう\n",
      "actual:    広島 味方が左サイドでボールを奪うと、Dヴィエイラがペナルティエリア左からマイナス方向へ折り返す。最後は柏がペナルティエリア手前からシュートを放つが、DFの体を張った守備に阻まれてしまう\n",
      "\n",
      "generated: 湘南 味方が左サイドの敵陣深くでボールを持ち、中央へパスを出す。すると、受けた町野がペナルティエリア手前の中央からシュートを放つ。しかし、相手DFにブロックされてしまう\n",
      "actual:    湘南 大橋がクサビのパスを受けてペナルティエリア左へ進入するも、小林の厳しいチェックに遭ってしまい、シュートまで持ち込めない\n",
      "\n",
      "generated: 鳥栖 山下がペナルティエリア手前の左からパスを出すと、仙頭が受けて右足でシュートを放つ。しかし、南にセーブされてしまう\n",
      "actual:    鳥栖 左サイドからのボールを山下がペナルティエリア手前の中央で収める。落としたボールを仙頭がダイレクトで狙うが、南にセーブされてしまう\n",
      "\n",
      "generated: 浦和 小泉が右サイドの敵陣深くへスルーパスを供給する。関根が走り込むも、精度を欠いてボールを失う\n",
      "actual:    浦和 小泉と関根の連係から右サイドを突破。ペナルティエリア右に関根が進入して攻撃を組み立てるが、最終的にボールを失う\n",
      "\n",
      "generated: 浦和 武藤が左サイドの敵陣中央でFKを獲得\n",
      "actual:    浦和 左サイドを巧みな連係で崩すと、左サイドの敵陣深くから山中がクロスを入れる。すると、ファーサイドで合わせたのは関根。ヘディングシュートをネットに突き刺した\n",
      "\n",
      "generated: 福岡 左CKを獲得する。キッカーの石津は右足でアウトスイングのクロスを供給するが、ニアサイドでDFにクリアされてしまう\n",
      "actual:    福岡 左CKを獲得する。キッカーの石津は右足でクロスを供給する。しかし、ゴールには至らない\n",
      "\n",
      "generated: 鳥栖 エドゥアルドが左サイドの敵陣深くからペナルティエリア内へ浮き球のパスを入れる。しかし、GKに直接キャッチされてしまう\n",
      "actual:    鳥栖 エドゥアルドが敵陣中央の左から左足で浮き球を送る。林が駆け上がるが、GKに処理されてしまう\n",
      "\n",
      "generated: FC東京 Dオリヴェイラがペナルティエリア左からシュートを放つ。しかし、ランゲラックのブロックに遭う\n",
      "actual:    FC東京 Dオリヴェイラがアダイウトンと連係し、ペナルティエリア左へ抜け出してシュートを放つ。ランゲラックがはじいたボールに反応した田川がペナルティエリア中央からダイレクトでシュートを放つも、またもランゲラックの好セーブに阻まれる\n",
      "\n",
      "generated: 徳島 岸本が右サイドの敵陣中央からペナルティエリア手前の中央へ鋭いパスを出す。受けた渡井はシュートを放つも、DFにブロックされてしまう\n",
      "actual:    徳島 藤原が細かい切り返しでDFをかわし、ペナルティエリア左から左足でクロスを供給する。しかし、ボールはファーサイドへ流れてしまう\n",
      "\n",
      "generated: 湘南 舘が右サイドの敵陣中央でドリブルを仕掛けるが、相手DFに阻まれてしまう\n",
      "actual:    湘南 舘が自陣でボールを奪ってカウンターを展開し、再びボールを受ける。舘はドリブルでペナルティエリア右に進入するも、最後は相手にボールをクリアされてしまう\n",
      "\n",
      "generated: 神戸 古橋が舘に対してプレッシャーを掛けて倒してしまう。このプレーが警告の対象となる\n",
      "actual:    湘南 ボールを運んだ舘がハーフウェーライン付近で後方から古橋に倒されてしまい、ファウルの判定となる\n",
      "\n",
      "generated: 柏 大南が自陣から右サイドの敵陣中央へロングボールを送る。味方が走り込むも、昌子が対応する\n",
      "actual:    柏 自陣でボールを奪った大南が右サイドを駆け上がり、倉田を振り切る。右サイドの敵陣深くまでボールを運んでクロスを上げるが、DFにブロックされる\n",
      "\n",
      "generated: 横浜FM 渡辺が右サイドの水沼にパスを送る。水沼はペナルティエリア右からクロスを上げるが、GKに直接キャッチされてしまう\n",
      "actual:    横浜FM 右サイドに開いた水沼がボールを受けると、素早く右足でクロスを入れる。しかし、Jスウォビィクに処理されてしまう\n",
      "\n",
      "generated: C大阪 キッカーの西川が左足でクロスを上げる。しかし、DFに頭でクリアされてしまう\n",
      "actual:    C大阪 右サイドで西川が高野に倒され、FKを獲得する。キッカーの西川がペナルティエリア内に蹴り込むが、シュートには至らない\n",
      "\n",
      "generated: 神戸 FKのキッカーは初瀬。左足でインスイングのクロスを供給するも、味方にはつながらない\n",
      "actual:    神戸 キッカーの初瀬が左足でふわりと浮かせたクロスをファーサイドへ送る。しかし、味方が走り込んでおらず、チャンスとはならない\n",
      "\n",
      "generated: 川崎F Lダミアンがペナルティエリア手前の中央から右足で浮き球のパスを入れる。しかし、味方にはつながらない\n",
      "actual:    川崎F ゴール!!!Jシミッチが敵陣中央からペナルティエリア手前の中央へくさびのパスを入れる。Lダミアンが後ろに流し、フリーとなっていた遠野がボールを受けてペナルティエリア中央へ進入する。DFにプレスを掛けられるが、倒れ込みつつシュートを放ち、先制点を決める\n",
      "\n",
      "generated: 広島 柴崎がペナルティエリア右から中央へ折り返すと、東が反応してシュートを放つ。しかし、枠の左に外れてしまう\n",
      "actual:    広島 味方が右方向からの低いクロスを送るが、ペナルティエリア中央の味方には合わない。それでも、上がってきた東がファーサイドで合わせ、シュートを放つ。しかし、枠をとらえられない\n",
      "\n",
      "generated: 大分 町田が右サイドの敵陣深くでボールを持ち、相手をかわしてペナルティエリア内へパスを出す。しかし、走り込んだ菊池にはつながらない\n",
      "actual:    大分 松本と町田の連係で右サイドを突破しようとするも、チャンスには至らない\n",
      "\n",
      "generated: 仙台 瀬古が前線で林に倒されてFKを獲得\n",
      "actual:    鳥栖 敵陣中央でボールを持った瀬古に対して、3人で囲んでボールを奪う。しかし、ファウルを取られてしまう\n",
      "\n",
      "generated: 浦和 関根が自陣から右サイドの敵陣深くへロングボールを供給する。しかし、精度を欠いてボールはゴールラインを割ってしまう\n",
      "actual:    浦和 ディフェンスラインで岩波と槙野が細かくパスをつなぎ、丁寧にビルドアップを図っている\n",
      "\n",
      "generated: 柏 キッカーの神谷が右足でクロスを送るも、ゴールには至らない\n",
      "actual:    柏 神谷が右足でクロスを送るが、相手にクリアされてしまう。もう一度右CKを獲得する\n",
      "\n",
      "generated: 柏 クリスティアーノが右サイドの敵陣深くでボールを持ち、ペナルティエリア内へ進入する。しかし、DFに阻まれてしまう\n",
      "actual:    柏 クリスティアーノが右サイドの敵陣深い位置でボールを持ち、ドリブル突破を図るも、相手を剥がし切れない\n",
      "\n",
      "generated: 神戸 井上が奥井に倒されてFKを獲得\n",
      "actual:    清水 ハーフウェーライン付近で奥井が井上と交錯。奥井にファウルの判定が下る\n",
      "\n",
      "generated: 横浜FC 手塚が自陣から前線へロングボールを送る。ペナルティエリア中央で受けた渡井がシュートを放つも、キムスンギュに防がれてしまう\n",
      "actual:    横浜FC 松尾が左サイドの敵陣中央から前線にボールを送ると、クレーベがペナルティエリア左で受ける。しかし、DFに囲まれてボールを失ってしまう\n",
      "\n",
      "generated: 仙台 右CKを獲得する。キッカーの松下が左足でクロスを供給するも、味方にはつながらない\n",
      "actual:    仙台 右CKを獲得する。キッカーの松下はインスイングのクロスを上げるも、ボールは前川にキャッチされてしまう\n",
      "\n",
      "generated: 横浜FM 左CKを獲得。キッカーのMジュニオールが右足でクロスを入れるも、ゴールには至らない\n",
      "actual:    横浜FM 左CKを獲得。キッカーのMジュニオールが右足でクロスを上げるが、GKにパンチングされてしまう\n",
      "\n",
      "generated: 浦和 ゴール!!!左CKを獲得。キッカーの小泉はショートコーナーを選択すると、山中へつなぐ。山中はペナルティエリア中央からクロスを供給すると、関根が頭で合わせる。これがDFに当たってコースが変わると、上福元が飛び込んでネットを揺らし、先制に成功\n",
      "actual:    浦和 ゴール!!!キッカーの小泉はショートコーナーを選択。山中が左サイドの敵陣深くから左足でカーブを掛けたクロスを供給する。走り込んだ関根がペナルティエリア中央からたたき付けるようにしてヘディングシュートを放つと、ボールはゴール右へと決まる。待望の先制点を奪取\n",
      "\n",
      "generated: 広島 左CKを獲得する。キッカーの森島が右足でクロスを入れるも、ゴールにはつながらない\n",
      "actual:    広島 相手のミスから左CKを獲得。キッカーの森島が右足でクロスを上げるが、相手にはね返されてしまう\n",
      "\n",
      "generated: 湘南 右CKを獲得。キッカーの高橋は左足でクロスを上げると、ゴール前で岡本がヘディングシュートを放つ。しかし、ゴール前の味方には合わず、前川にキャッチされてしまう\n",
      "actual:    湘南 右CKを獲得。キッカーの高橋が左足でインスイングの高く浮かせたクロスを送ると、岡本が力強いヘディングシュートを放つ。しかし、ここも前川に処理されてしまう\n",
      "\n",
      "generated: 鹿島 ゴール!!!右CKを獲得。キッカーの永戸は左足でクロスを上げると、ファーサイドに上がった選手がヘディングシュートを放つ。これが上福元のファインセーブに遭うが、こぼれ球を拾った町田がペナルティエリア中央から頭で合わせる。ボールはネットを揺らし、先制に成功\n",
      "actual:    鹿島 ゴール!!!右CKを獲得。キッカーの永戸が左足でインスイングのクロスを入れると、タイミングよく走り込んだ町田が打点の高いヘディングシュートを放つ。ボールは上福元の手をはじいてゴール右に決まる\n",
      "\n",
      "generated: 柏 右CKを獲得。キッカーの神谷がクロスを入れると、Mサヴィオが飛び込む。しかし、得点には至らない\n",
      "actual:    柏 右サイドからのCKを獲得。キッカーの神谷が右足で大きなクロスをファーサイドに蹴り込む。だが、得点にはつながらず\n",
      "\n",
      "generated: 川崎F キッカーの田中が右足でクロスを上げるも、ニアサイドで相手にクリアされてしまう\n",
      "actual:    川崎F 左CKを獲得。キッカーの田中がインスイングのクロスを供給するも、相手にクリアされる\n",
      "\n",
      "generated: 柏 Mサヴィオが左サイドの敵陣中央からスルーパスを送る。受けた味方はすぐにペナルティエリア内へ走り込むが、ボールはそのままゴールラインを割ってしまう\n",
      "actual:    柏 Mサヴィオが敵陣中央の左からペナルティエリア左へ鋭いスルーパスを出す。江坂が抜け出してボールを受けようとするが、わずかに合わない\n",
      "\n",
      "generated: 湘南 高橋が自陣から左サイドの敵陣深くへロングボールを送る。しかし、相手DFにブロックされてしまう\n",
      "actual:    湘南 高橋が自陣の左サイドから左サイドのスペースへグラウンダーのロングボールを供給。これに走り込んだ山田が大橋につなぐと、その勢いのままに大橋はペナルティエリア左への進入を試みる。しかし、相手にうまく対処されてしまう\n",
      "\n",
      "generated: 柏 敵陣中央でFKを獲得。キッカーの神谷が左足でペナルティエリア内へ浮き球のパスを入れると、ゴール前で上島がヘディングシュートを放つ。しかし、南にパンチングではじかれてしまう\n",
      "actual:    柏 敵陣中央の右でFKを得る。キッカーがゴール前へ低めのクロスを蹴り込む。上島がダイビングヘッドで合わせる。しかし、左隅に飛んだシュートは南に防がれてしまう\n",
      "\n",
      "generated: 鳥栖 敵陣中央で中野嘉が田中に倒されてFKを獲得\n",
      "actual:    川崎F 田中の中野嘉に対して後ろから突破を止めたプレーが警告の対象となる\n",
      "\n",
      "generated: 名古屋 前田がペナルティエリア手前の左から右足でグラウンダーのシュートを放つも、枠をとらえられない\n",
      "actual:    名古屋 敵陣でボールを奪うと、カウンターの流れになる。左で前田が仕掛けてペナルティエリア手前へパスを出すと、マテウスがシュートを放つ。しかし、クロスバーを越えてしまう\n",
      "\n",
      "generated: 大分 長谷川が右サイドの敵陣中央からペナルティエリア内へ浮き球のパスを入れる。高澤が頭で合わせるも、DFに当たってしまう\n",
      "actual:    大分 右からゴール前へ味方がクロスを入れる。高澤が相手DFと競り合いながら頭で合わせるが、ランゲラックに処理されてしまう\n",
      "\n",
      "generated: C大阪 豊川が右サイドの敵陣中央でエドゥアルドに倒されてFKを獲得\n",
      "actual:    鳥栖 エドゥアルドが豊川に後ろからタックルし、警告を受ける\n",
      "\n",
      "generated: 福岡 金森が右サイドの敵陣深くからクロスを上げる。しかし、味方にはつながらない\n",
      "actual:    福岡 金森がボールを拾い、右サイドの敵陣深くから右足でクロスを供給する。しかし、ゴールにはつながらない\n",
      "\n",
      "generated: 浦和 関根がペナルティエリア手前の左から右足で浮き球を送ると、走り込んだ松田陸が飛び込む。しかし、DFにブロックされてしまう\n",
      "actual:    浦和 ペナルティエリア手前で伊藤敦と小泉を中心にパスを回すが、シュートまで持ち込めず、ボールを失う\n",
      "\n",
      "generated: 清水 左CKを獲得する。キッカーの中村は右足でクロスを上げると、ゴール前でヴァウドが反応する。しかし、得点には至らない\n",
      "actual:    清水 キッカーの中村が右足でファーサイドにクロスを入れ、ヴァウドが頭で折り返すが、DFにはじかれる\n",
      "\n",
      "generated: 広島 Dヴィエイラが右サイドの敵陣深くからペナルティエリア中央へ鋭いパスを送る。しかし、味方にはつながらない\n",
      "actual:    広島 野上が前線へふわりと浮かせたボールを送ると、Dヴィエイラが収めようとする。だが、DFに対応されてしまう\n",
      "\n",
      "generated: 川崎F 旗手が右サイドの敵陣深くからペナルティエリア中央へクロスを入れる。脇坂が合わせるも、高木にパンチングではじかれてしまう\n",
      "actual:    川崎F 敵陣の深くでパスを回すと、最後はペナルティエリア左角付近から登里がシュートを放つ。これは高木にセーブされるが、こぼれ球を拾って2次攻撃を仕掛ける。しかし、シュートまでは持ち込めない\n",
      "\n",
      "generated: 川崎F Lダミアンがペナルティエリア手前の中央からシュートを放つ。しかし、枠の右へ外れてしまう\n",
      "actual:    川崎F 遠野がペナルティエリア手前の中央から積極的に右足を振り抜くも、枠の上に外れる\n",
      "\n",
      "generated: 福岡 志知が左サイドの敵陣深くからクロスを上げると、ペナルティエリア中央で山岸が合わせる。しかし、枠をとらえられない\n",
      "actual:    福岡 志知が左サイドの敵陣深くでボールを持ち、クロスをニアサイドに入れる。山岸が足を出して合わせるが、枠に飛ばない\n",
      "\n",
      "generated: 横浜FC 松尾がペナルティエリア左から中央へ折り返す。しかし、DFにクリアされてしまう\n",
      "actual:    横浜FC 松尾がドリブルで左サイドを駆け上がる。ペナルティエリア左まで進入して右足でクロスを上げるが、飯野にブロックされてしまう\n",
      "\n",
      "generated: 福岡 Eサロモンソンが右サイドの敵陣深くからグラウンダーのクロスを入れる。山岸がペナルティエリア中央でシュートを放つも、枠をとらえられない\n",
      "actual:    福岡 Eサロモンソンが右サイドの敵陣深くからペナルティエリア中央へふわりとしたクロスを入れる。スペースに走り込んできた山岸がダイレクトでボレーシュートを放つが、枠から大きく外れてしまう。決定機を決められず、山岸はピッチに寝転んで悔しがる\n",
      "\n",
      "generated: 大分 伊佐が左サイドの敵陣中央でドリブルを仕掛けるが、DFに阻まれて左CKを獲得する\n",
      "actual:    大分 伊佐が味方からのロングボールを収めて左サイドで攻撃を展開。敵陣深くまで飛び出してきたキムスンギュをかわしてペナルティエリア左に進入するが、川口の体を張ったディフェンスに阻まれてしまう\n",
      "\n",
      "generated: G大阪 パトリックが敵陣中央で倒されてFKを獲得\n",
      "actual:    G大阪 パトリックが競り合った輪湖の対応を受けて倒され、ペナルティエリア手前の右でFKを獲得する\n",
      "\n",
      "generated: 鳥栖 田代が右サイドの敵陣中央からペナルティエリア内へ低い弾道のクロスを入れる。本田が走り込むが、DFにクリアされてしまう\n",
      "actual:    鳥栖 樋口が右サイドの敵陣中央から右足でクロスを上げると、ペナルティエリア内で本田がパスを供給。山下が受けるが、DFにボールを奪われてしまう\n",
      "\n",
      "generated: 横浜FM 左サイドで天野がボールを持つと、ペナルティエリア中央へクロスを入れる。これは相手のブロックに遭うが、こぼれ球を拾って最後はオッティがシュートを放つが、谷の好セーブに遭い、得点には至らない\n",
      "actual:    横浜FM 天野が左サイドの敵陣中央をドリブルで駆け上がり、ファーサイドの前田へピンポイントでクロスを蹴り込む。前田が飛び込んで合わせるも、ヘディングシュートは谷に阻まれてしまう\n",
      "\n",
      "generated: C大阪 西川が左サイドの敵陣中央からクロスを上げる。しかし、GKにキャッチされてしまう\n",
      "actual:    C大阪 西川が右サイドの敵陣中央から左足でグラウンダーの速いクロスを送る。しかし、GKにキャッチされてしまう\n",
      "\n",
      "generated: 札幌 右CKを獲得。キッカーの福森は左足でクロスを上げると、ゴール前で反応した柳がヘディングシュートを放つ。しかし、枠をとらえられない\n",
      "actual:    札幌 右サイドからのCKを得る。菅野も上がって得点を狙う。キッカーの福森が左足で高精度のクロスを供給。競り合いながら柳が頭で合わせるも、シュートは枠を外れてしまう\n",
      "\n",
      "generated: 神戸 山口がペナルティエリア手前の中央から左足で鋭いシュートを放つ。しかし、高木に対応されてしまう\n",
      "actual:    神戸 古橋がペナルティエリア手前の左から左足でシュートを放つも、高木にキャッチされてしまう\n",
      "\n",
      "generated: G大阪 敵陣中央でFKを獲得。キッカーの山本が左足でペナルティエリア内へ浮き球を送るも、Dヴィエイラにクリアされてしまう\n",
      "actual:    G大阪 キッカーの山本が右足で浮き球を送る。だが、Dヴィエイラにクリアされてしまう\n",
      "\n",
      "generated: 名古屋 左サイドを中心にパスをつなぐと、相馬が左サイドの敵陣深くへ抜け出してクロスを入れる。しかし、相手DFに阻まれてしまう\n",
      "actual:    名古屋 相馬が味方と連係してペナルティエリア左へ抜け出すが、中村拓に体を入れられてしまってボールをコントロールできない\n",
      "\n",
      "generated: 広島 エゼキエウがペナルティエリア手前の右からスルーパスを送る。反応したチョンソンリョンが走り込むも、シュートには持ち込めない\n",
      "actual:    広島 自陣でボールを奪い、エゼキエウが敵陣中央までボールを運ぶ。ペナルティエリア左へスルーパスを出すが、Jサントスと息が合わず、GKに処理される\n",
      "\n",
      "generated: 湘南 大橋が右サイドの敵陣中央からペナルティエリア内へクロスを入れる。町野が頭で合わせるも、枠をとらえられない\n",
      "actual:    湘南 右サイドで正確にボールを回すと、岡本のパスを受けた大橋がペナルティエリア右脇から右足で鋭い低めのクロスを供給。これに反応したのは町野。ニアサイドで力強いヘディングシュートを放つが、惜しくも枠の右に外れてしまう\n",
      "\n",
      "generated: 神戸 櫻内が自陣からロングボールを送ると、ドリブルで持ち上がる。そのままペナルティエリア手前の中央まで駆け上がってくるが、シュートには至らない\n",
      "actual:    神戸 櫻内が自陣から前線の古橋へロングフィードを送るも、ボールは長くなり、Jスウォビィクに処理されてしまう\n",
      "\n",
      "generated: 横浜FM 喜田が敵陣中央でボールを奪い、水沼に預ける。水沼はペナルティエリア左からクロスを入れるも、DFにクリアされてしまう\n",
      "actual:    横浜FM 喜田がペナルティエリア手前からパスを出すと、水沼がペナルティエリア右で受けて左足で浮き球のパスを送る。しかし、ゴール前のDFにヘディングでクリアされてしまう\n",
      "\n",
      "generated: G大阪 チアゴアウベスが左サイドの敵陣中央からクロスを供給する。しかし、ペナルティエリア内のDFにブロックされてしまう\n",
      "actual:    G大阪 チアゴアウベスが左サイドの敵陣中央から左足でクロスを上げるが、飛び出してきた大迫にパンチングでクリアされてしまう\n",
      "\n",
      "generated: C大阪 丸橋がペナルティエリア手前の左からシュートを放つ。しかし、DFにブロックされてしまう。こぼれ球を拾った豊川がペナルティエリア中央でシュートを放つも、相手にブロックされる\n",
      "actual:    C大阪 右サイドの敵陣深くからスローインを獲得すると、藤田がロングスローを入れる。しかし、DFにヘディングでクリアされてしまう。こぼれ球に反応した清武がシュートを放つが、ブロックされてしまう。さらにこぼれ球に反応した豊川が左足でボレーシュートを放つが、得点には至らない\n",
      "\n",
      "generated: 福岡 Eサロモンソンが左CKを獲得する。キッカーのEサロモンソンはクロスを供給するも、DFにクリアされてしまう\n",
      "actual:    福岡 キッカーのEサロモンソンはショートコーナーを選択する。しかし、ゴールには至らない\n",
      "\n",
      "generated: 横浜FM 右サイドでボールを受けた天野。ショートカウンターから右足でクロスを入れるも、Jスウォビィクにキャッチされてしまう\n",
      "actual:    横浜FM Jスウォビィクがボールをこぼしたところを仲川が見逃さず、ボールを奪ってチャンスを迎える。最後は天野が右からクロスを送るも、相手にゴール前でクリアされてしまい、得点には至らない\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output, target, input in zip(outputs, targets, inputs):\n",
    "    print(\"generated: \" + output.upper())\n",
    "    print(\"actual:    \" + target.upper())\n",
    "    # print(\"body:      \" + input)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
